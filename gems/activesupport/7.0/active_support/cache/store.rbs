# !!! GENERATED CODE !!!
# Please see generators/rails-generator

class ActiveSupport::Cache::Store
  alias silence? silence
  private def self.retrieve_pool_options: (untyped options) -> untyped
  private def self.ensure_connection_pool_added!: () -> untyped
  # Creates a new cache.
  #
  # ==== Options
  #
  # * +:namespace+ - Sets the namespace for the cache. This option is
  #   especially useful if your application shares a cache with other
  #   applications.
  # * +:coder+ - Replaces the default cache entry serialization mechanism
  #   with a custom one. The +coder+ must respond to +dump+ and +load+.
  #   Using a custom coder disables automatic compression.
  #
  # Any other specified options are treated as default options for the
  # relevant cache operations, such as #read, #write, and #fetch.
  def initialize: (?untyped? options) -> void
  # Silences the logger.
  def silence!: () -> self
  # Silences the logger within a block.
  def mute: () { () -> untyped } -> untyped
  # Fetches data from the cache, using the given key. If there is data in
  # the cache with the given key, then that data is returned.
  #
  # If there is no such data in the cache (a cache miss), then +nil+ will be
  # returned. However, if a block has been passed, that block will be passed
  # the key and executed in the event of a cache miss. The return value of the
  # block will be written to the cache under the given cache key, and that
  # return value will be returned.
  #
  #   cache.write('today', 'Monday')
  #   cache.fetch('today')  # => "Monday"
  #
  #   cache.fetch('city')   # => nil
  #   cache.fetch('city') do
  #     'Duckburgh'
  #   end
  #   cache.fetch('city')   # => "Duckburgh"
  #
  # ==== Options
  #
  # Internally, +fetch+ calls #read_entry, and calls #write_entry on a cache
  # miss. Thus, +fetch+ supports the same options as #read and #write.
  # Additionally, +fetch+ supports the following options:
  #
  # * <tt>force: true</tt> - Forces a cache "miss," meaning we treat the
  #   cache value as missing even if it's present. Passing a block is
  #   required when +force+ is true so this always results in a cache write.
  #
  #     cache.write('today', 'Monday')
  #     cache.fetch('today', force: true) { 'Tuesday' } # => 'Tuesday'
  #     cache.fetch('today', force: true) # => ArgumentError
  #
  #   The +:force+ option is useful when you're calling some other method to
  #   ask whether you should force a cache write. Otherwise, it's clearer to
  #   just call +write+.
  #
  # * <tt>skip_nil: true</tt> - Prevents caching a nil result:
  #
  #     cache.fetch('foo') { nil }
  #     cache.fetch('bar', skip_nil: true) { nil }
  #     cache.exist?('foo') # => true
  #     cache.exist?('bar') # => false
  #
  # * +:race_condition_ttl+ - Specifies the number of seconds during which
  #   an expired value can be reused while a new value is being generated.
  #   This can be used to prevent race conditions when cache entries expire,
  #   by preventing multiple processes from simultaneously regenerating the
  #   same entry (also known as the dog pile effect).
  #
  #   When a process encounters a cache entry that has expired less than
  #   +:race_condition_ttl+ seconds ago, it will bump the expiration time by
  #   +:race_condition_ttl+ seconds before generating a new value. During
  #   this extended time window, while the process generates a new value,
  #   other processes will continue to use the old value. After the first
  #   process writes the new value, other processes will then use it.
  #
  #   If the first process errors out while generating a new value, another
  #   process can try to generate a new value after the extended time window
  #   has elapsed.
  #
  #     # Set all values to expire after one minute.
  #     cache = ActiveSupport::Cache::MemoryStore.new(expires_in: 1.minute)
  #
  #     cache.write('foo', 'original value')
  #     val_1 = nil
  #     val_2 = nil
  #     sleep 60
  #
  #     Thread.new do
  #       val_1 = cache.fetch('foo', race_condition_ttl: 10.seconds) do
  #         sleep 1
  #         'new value 1'
  #       end
  #     end
  #
  #     Thread.new do
  #       val_2 = cache.fetch('foo', race_condition_ttl: 10.seconds) do
  #         'new value 2'
  #       end
  #     end
  #
  #     cache.fetch('foo') # => "original value"
  #     sleep 10 # First thread extended the life of cache by another 10 seconds
  #     cache.fetch('foo') # => "new value 1"
  #     val_1 # => "new value 1"
  #     val_2 # => "original value"
  #
  def fetch: (untyped name, ?untyped? options) ?{ () -> untyped } -> untyped
  # Reads data from the cache, using the given key. If there is data in
  # the cache with the given key, then that data is returned. Otherwise,
  # +nil+ is returned.
  #
  # Note, if data was written with the <tt>:expires_in</tt> or
  # <tt>:version</tt> options, both of these conditions are applied before
  # the data is returned.
  #
  # ==== Options
  #
  # * +:version+ - Specifies a version for the cache entry. If the cached
  #   version does not match the requested version, the read will be treated
  #   as a cache miss. This feature is used to support recyclable cache keys.
  #
  # Other options will be handled by the specific cache store implementation.
  def read: (untyped name, ?untyped? options) -> untyped
  # Reads multiple values at once from the cache. Options can be passed
  # in the last argument.
  #
  # Some cache implementation may optimize this method.
  #
  # Returns a hash mapping the names provided to the values found.
  def read_multi: (*untyped names) -> untyped
  # Cache Storage API to write multiple values at once.
  def write_multi: (untyped hash, ?untyped? options) -> untyped
  # Fetches data from the cache, using the given keys. If there is data in
  # the cache with the given keys, then that data is returned. Otherwise,
  # the supplied block is called for each key for which there was no data,
  # and the result will be written to the cache and returned.
  # Therefore, you need to pass a block that returns the data to be written
  # to the cache. If you do not want to write the cache when the cache is
  # not found, use #read_multi.
  #
  # Returns a hash with the data for each of the names. For example:
  #
  #   cache.write("bim", "bam")
  #   cache.fetch_multi("bim", "unknown_key") do |key|
  #     "Fallback value for key: #{key}"
  #   end
  #   # => { "bim" => "bam",
  #   #      "unknown_key" => "Fallback value for key: unknown_key" }
  #
  # Options are passed to the underlying cache implementation. For example:
  #
  #   cache.fetch_multi("fizz", expires_in: 5.seconds) do |key|
  #     "buzz"
  #   end
  #   # => {"fizz"=>"buzz"}
  #   cache.read("fizz")
  #   # => "buzz"
  #   sleep(6)
  #   cache.read("fizz")
  #   # => nil
  def fetch_multi: (*untyped names) { (untyped) -> untyped } -> untyped
  # Writes the value to the cache with the key. The value must be supported
  # by the +coder+'s +dump+ and +load+ methods.
  #
  # By default, cache entries larger than 1kB are compressed. Compression
  # allows more data to be stored in the same memory footprint, leading to
  # fewer cache evictions and higher hit rates.
  #
  # ==== Options
  #
  # * <tt>compress: false</tt> - Disables compression of the cache entry.
  #
  # * +:compress_threshold+ - The compression threshold, specified in bytes.
  #   \Cache entries larger than this threshold will be compressed. Defaults
  #   to +1.kilobyte+.
  #
  # * +:expires_in+ - Sets a relative expiration time for the cache entry,
  #   specified in seconds. +:expire_in+ and +:expired_in+ are aliases for
  #   +:expires_in+.
  #
  #     cache = ActiveSupport::Cache::MemoryStore.new(expires_in: 5.minutes)
  #     cache.write(key, value, expires_in: 1.minute) # Set a lower value for one entry
  #
  # * +:expires_at+ - Sets an absolute expiration time for the cache entry.
  #
  #     cache = ActiveSupport::Cache::MemoryStore.new
  #     cache.write(key, value, expires_at: Time.now.at_end_of_hour)
  #
  # * +:version+ - Specifies a version for the cache entry. When reading
  #   from the cache, if the cached version does not match the requested
  #   version, the read will be treated as a cache miss. This feature is
  #   used to support recyclable cache keys.
  #
  # Other options will be handled by the specific cache store implementation.
  def write: (untyped name, untyped value, ?untyped? options) -> untyped
  # Deletes an entry in the cache. Returns +true+ if an entry is deleted.
  #
  # Options are passed to the underlying cache implementation.
  def delete: (untyped name, ?untyped? options) -> untyped
  # Deletes multiple entries in the cache.
  #
  # Options are passed to the underlying cache implementation.
  def delete_multi: (untyped names, ?untyped? options) -> untyped
  # Returns +true+ if the cache contains an entry for the given key.
  #
  # Options are passed to the underlying cache implementation.
  def exist?: (untyped name, ?untyped? options) -> untyped
  def new_entry: (untyped value, ?untyped? options) -> untyped
  # Deletes all entries with keys matching the pattern.
  #
  # Options are passed to the underlying cache implementation.
  #
  # Some implementations may not support this method.
  def delete_matched: (untyped matcher, ?untyped? options) -> untyped
  # Increments an integer value in the cache.
  #
  # Options are passed to the underlying cache implementation.
  #
  # Some implementations may not support this method.
  def increment: (untyped name, ?::Integer amount, ?untyped? options) -> untyped
  # Decrements an integer value in the cache.
  #
  # Options are passed to the underlying cache implementation.
  #
  # Some implementations may not support this method.
  def decrement: (untyped name, ?::Integer amount, ?untyped? options) -> untyped
  # Cleans up the cache by removing expired entries.
  #
  # Options are passed to the underlying cache implementation.
  #
  # Some implementations may not support this method.
  def cleanup: (?untyped? options) -> untyped
  # Clears the entire cache. Be careful with this method since it could
  # affect other processes if shared cache is being used.
  #
  # The options hash is passed to the underlying cache implementation.
  #
  # Some implementations may not support this method.
  def clear: (?untyped? options) -> untyped
  private def default_coder: () -> untyped
  # Adds the namespace defined in the options to a pattern designed to
  # match keys. Implementations that support delete_matched should call
  # this method to translate a pattern that matches names into one that
  # matches namespaced keys.
  private def key_matcher: (untyped pattern, untyped options) -> untyped
  # Reads an entry from the cache implementation. Subclasses must implement
  # this method.
  private def read_entry: (untyped key, **untyped options) -> untyped
  # Writes an entry to the cache implementation. Subclasses must implement
  # this method.
  private def write_entry: (untyped key, untyped entry, **untyped options) -> untyped
  private def serialize_entry: (untyped entry, **untyped options) -> untyped
  private def deserialize_entry: (untyped payload) -> (nil | untyped)
  # Reads multiple entries from the cache implementation. Subclasses MAY
  # implement this method.
  private def read_multi_entries: (untyped names, **untyped options) -> untyped
  # Writes multiple entries to the cache implementation. Subclasses MAY
  # implement this method.
  private def write_multi_entries: (untyped hash, **untyped options) -> untyped
  # Deletes an entry from the cache implementation. Subclasses must
  # implement this method.
  private def delete_entry: (untyped key, **untyped options) -> untyped
  # Deletes multiples entries in the cache implementation. Subclasses MAY
  # implement this method.
  private def delete_multi_entries: (untyped entries, **untyped options) -> untyped
  # Merges the default options with ones specific to a method call.
  private def merged_options: (untyped call_options) -> untyped
  # Normalize aliased options to their canonical form
  private def normalize_options: (untyped options) -> untyped
  # Expands and namespaces the cache key. May be overridden by
  # cache stores to do additional normalization.
  private def normalize_key: (untyped key, ?untyped? options) -> untyped
  # Prefix the key with a namespace string:
  #
  #   namespace_key 'foo', namespace: 'cache'
  #   # => 'cache:foo'
  #
  # With a namespace block:
  #
  #   namespace_key 'foo', namespace: -> { 'cache' }
  #   # => 'cache:foo'
  private def namespace_key: (untyped key, ?untyped? options) -> untyped
  # Expands key to be a consistent string value. Invokes +cache_key+ if
  # object responds to +cache_key+. Otherwise, +to_param+ method will be
  # called. If the key is a Hash, then keys will be sorted alphabetically.
  private def expanded_key: (untyped key) -> untyped
  private def normalize_version: (untyped key, ?untyped? options) -> untyped
  private def expanded_version: (untyped key) -> untyped
  private def instrument: (untyped operation, untyped key, ?untyped? options) { (untyped) -> untyped } -> untyped
  private def handle_expired_entry: (untyped entry, untyped key, untyped options) -> untyped
  private def get_entry_value: (untyped entry, untyped name, untyped options) -> untyped
  private def save_block_result_to_cache: (untyped name, untyped options) { (untyped) -> untyped } -> untyped
  attr_reader silence: untyped
  attr_reader options: untyped
  def self.logger: () -> untyped
  def logger: () -> untyped
  def self.logger=: (untyped val) -> untyped
  def logger=: (untyped val) -> untyped
end
